{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBQj4lvYKchpO9xm0pPp6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamanVerma27/India_AQI_Analysis-Project/blob/main/aqi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOzpW4H2m8Ka"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_date, when, round, expr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spark_session():\n",
        "    \"\"\"\n",
        "    Create a Spark session for data processing\n",
        "    \"\"\"\n",
        "    return SparkSession.builder \\\n",
        "        .appName(\"IndianAirQualityAnalysis\") \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "WqqyfmDPnGZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_air_quality_data(spark, file_path):\n",
        "    \"\"\"\n",
        "    Load air quality dataset with proper schema\n",
        "    \"\"\"\n",
        "    # Read the CSV file\n",
        "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "    # Convert Date column to date type using expr()\n",
        "    df = df.withColumn(\"Date\", expr(\"to_date(Date)\"))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "ZvSSAWgpnSz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initial_data_exploration(df):\n",
        "    \"\"\"\n",
        "    Perform initial data exploration and basic cleaning\n",
        "    \"\"\"\n",
        "    # Print basic information about the dataset\n",
        "    print(\"Total number of records:\", df.count())\n",
        "    print(\"\\nUnique Cities:\", df.select(\"City\").distinct().count())\n",
        "\n",
        "    # Date range using expr()\n",
        "    print(\"\\nDate Range:\")\n",
        "    df.select(\n",
        "        expr(\"min(Date) as min_date\"),\n",
        "        expr(\"max(Date) as max_date\")\n",
        "    ).show()\n",
        "\n",
        "    # Basic column statistics\n",
        "    print(\"\\nColumn Statistics:\")\n",
        "    columns_to_analyze = [\"PM2.5\", \"PM10\", \"NO2\", \"AQI\"]\n",
        "    for column in columns_to_analyze:\n",
        "        print(f\"\\n{column} Column Statistics:\")\n",
        "        # Enclose column name in backticks to handle special characters\n",
        "        df.select(\n",
        "            expr(f\"avg(`{column}`) as mean\"),\n",
        "            expr(f\"stddev(`{column}`) as std\"),\n",
        "            expr(f\"min(`{column}`) as min\"),\n",
        "            expr(f\"max(`{column}`) as max\")\n",
        "        ).show()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "pUz26OLxoWQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Create Spark Session\n",
        "    spark = create_spark_session()\n",
        "\n",
        "    # Load Data - replace with your actual file path\n",
        "    file_path = \"city_day.csv\"\n",
        "    air_quality_df = load_air_quality_data(spark, file_path)\n",
        "\n",
        "    # Perform Initial Exploration\n",
        "    initial_data_exploration(air_quality_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAf9Ompmohec",
        "outputId": "be1ffd42-340c-45e6-b784-09cfc770c2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of records: 29531\n",
            "\n",
            "Unique Cities: 26\n",
            "\n",
            "Date Range:\n",
            "+----------+----------+\n",
            "|  min_date|  max_date|\n",
            "+----------+----------+\n",
            "|2015-01-01|2020-07-01|\n",
            "+----------+----------+\n",
            "\n",
            "\n",
            "Column Statistics:\n",
            "\n",
            "PM2.5 Column Statistics:\n",
            "+-----------------+-----------------+----+------+\n",
            "|             mean|              std| min|   max|\n",
            "+-----------------+-----------------+----+------+\n",
            "|67.45057794890272|64.66144945715128|0.04|949.99|\n",
            "+-----------------+-----------------+----+------+\n",
            "\n",
            "\n",
            "PM10 Column Statistics:\n",
            "+------------------+-----------------+----+------+\n",
            "|              mean|              std| min|   max|\n",
            "+------------------+-----------------+----+------+\n",
            "|118.12710293078102|90.60510971779476|0.01|1000.0|\n",
            "+------------------+-----------------+----+------+\n",
            "\n",
            "\n",
            "NO2 Column Statistics:\n",
            "+------------------+------------------+----+------+\n",
            "|              mean|               std| min|   max|\n",
            "+------------------+------------------+----+------+\n",
            "|28.560659061126763|24.474745795589442|0.01|362.21|\n",
            "+------------------+------------------+----+------+\n",
            "\n",
            "\n",
            "AQI Column Statistics:\n",
            "+-----------------+------------------+----+------+\n",
            "|             mean|               std| min|   max|\n",
            "+-----------------+------------------+----+------+\n",
            "|166.4635814889336|140.69658509414992|13.0|2049.0|\n",
            "+-----------------+------------------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when, round, expr, avg, stddev, max as spark_max\n",
        "\n",
        "def clean_air_quality_data(df):\n",
        "    \"\"\"\n",
        "    Clean and preprocess air quality data\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Input air quality DataFrame\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: Cleaned and processed DataFrame\n",
        "    \"\"\"\n",
        "    # Handle missing values - Use backticks to escape special characters\n",
        "    cleaned_df = df.fillna({\n",
        "        \"`PM2.5`\": 0,  # Changed \"PM2.5\" to \"`PM2.5`\"\n",
        "        \"`PM10`\": 0,  # Changed \"PM10\" to \"`PM10`\"\n",
        "        \"NO2\": 0,\n",
        "        \"AQI\": 0\n",
        "    })\n",
        "\n",
        "    # Create pollution level categories\n",
        "    # Changed the when condition to check if PM2.5 is less than or equal to 30 for \"Good\" category\n",
        "    cleaned_df = cleaned_df.withColumn(\"PM2.5_Category\",\n",
        "        when(col(\"`PM2.5`\") <= 30, \"Good\")\n",
        "        .when((col(\"`PM2.5`\") > 30) & (col(\"`PM2.5`\") <= 60), \"Moderate\")\n",
        "        .when((col(\"`PM2.5`\") > 60) & (col(\"`PM2.5`\") <= 90), \"Unhealthy for Sensitive Groups\")\n",
        "        .otherwise(\"Unhealthy\")\n",
        "    )\n",
        "\n",
        "    # Round numeric columns  - Use backticks to escape special characters\n",
        "    numeric_columns = [\"`PM2.5`\", \"`PM10`\", \"NO2\", \"AQI\"] # Changed \"PM2.5\" to \"`PM2.5`\" and \"PM10\" to \"`PM10`\"\n",
        "    for column in numeric_columns:\n",
        "        cleaned_df = cleaned_df.withColumn(column, round(col(column), 2))\n",
        "\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "oecAuIw5o44O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_city_pollution(df):\n",
        "    \"\"\"\n",
        "    Analyze pollution levels by city\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): Cleaned air quality DataFrame\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: City-wise pollution analysis\n",
        "    \"\"\"\n",
        "    city_pollution_analysis = df.groupBy(\"City\").agg(\n",
        "        round(avg(\"`PM2.5`\"), 2).alias(\"Avg_PM2.5\"),  # Changed \"PM2.5\" to \"`PM2.5`\"\n",
        "        round(stddev(\"`PM2.5`\"), 2).alias(\"Std_PM2.5\"),  # Changed \"PM2.5\" to \"`PM2.5`\"\n",
        "        round(spark_max(\"`PM2.5`\"), 2).alias(\"Max_PM2.5\"),  # Changed \"PM2.5\" to \"`PM2.5`\"\n",
        "        round(avg(\"AQI\"), 2).alias(\"Avg_AQI\"),\n",
        "        expr(\"count(*) as Total_Measurements\")\n",
        "    ).orderBy(\"Avg_AQI\", ascending=False)\n",
        "\n",
        "    return city_pollution_analysis"
      ],
      "metadata": {
        "id": "PR14Vzy7sk2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Create Spark Session\n",
        "    spark = create_spark_session()\n",
        "\n",
        "    # Load Data\n",
        "    file_path = \"city_day.csv\"\n",
        "    air_quality_df = load_air_quality_data(spark, file_path)\n",
        "\n",
        "    # Clean Data\n",
        "    cleaned_df = clean_air_quality_data(air_quality_df)\n",
        "\n",
        "    # Analyze City-wise Pollution\n",
        "    city_pollution = analyze_city_pollution(cleaned_df)\n",
        "\n",
        "    # Show results\n",
        "    city_pollution.show(10)\n",
        "\n",
        "    # Optional: Save results\n",
        "    city_pollution.write.csv(\"city_pollution_analysis.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxKoNtZUsv2u",
        "outputId": "41c32fdf-bb67-41d2-9cef-1b2fbe86d3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+---------+-------+------------------+\n",
            "|     City|Avg_PM2.5|Std_PM2.5|Max_PM2.5|Avg_AQI|Total_Measurements|\n",
            "+---------+---------+---------+---------+-------+------------------+\n",
            "|Ahmedabad|    46.64|    45.41|   381.69| 300.22|              2009|\n",
            "|    Delhi|   117.08|    82.95|   685.36|  258.2|              2009|\n",
            "|  Lucknow|   104.14|    81.35|   742.67| 205.39|              2009|\n",
            "| Gurugram|   106.36|   100.27|   949.99| 194.82|              1679|\n",
            "|    Patna|   102.16|    97.55|    645.5| 189.07|              1858|\n",
            "| Guwahati|    63.56|    61.64|   916.67| 138.16|               502|\n",
            "|   Jaipur|    53.91|     27.0|   311.35| 131.28|              1114|\n",
            "|  Talcher|    49.19|    51.13|   354.44| 130.46|               925|\n",
            "|  Kolkata|    60.01|    58.64|   304.74| 130.21|               814|\n",
            "|   Bhopal|     48.5|    31.19|   136.42| 127.77|               289|\n",
            "+---------+---------+---------+---------+-------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}